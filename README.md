
---
title: "Promptly ‚Äî Outcome‚ÄëFirst Prompt Engineering"
author: "Promptly Contributors"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: false
    theme: readable
    df_print: paged
---

## What is Promptly?
Promptly is a visualization‚Äëfirst, outcome‚Äëdriven prompt engineering workbench. You define the **task spec** and **test cases**; Promptly then **searches**, **tests**, and **improves** prompts so model behavior converges toward the **ideal output you define**. It replaces ad‚Äëhoc prompting with **evidence‚Äëbacked iteration**.

### Why it matters
- **Outcome‚Äëfirst** ‚Äî Align generation with your acceptance criteria.
- **Evidence over intuition** ‚Äî KPIs and tests tell you what works.  
- **Reusable pipeline** ‚Äî Templated Spec, Tests, KPIs, and Version Evolution.

---

## Core Features
- **Prompt Enhancer** ‚Äî Structures intent, optionally injects CoT for reasoning tasks, supports parameterized placeholders.
- **Validator & KPIs** ‚Äî Accuracy, F1, Pass Rate, Token Cost, Progress (extensible scoring).
- **Version Evolution** ‚Äî Logs each change and its **ŒîAccuracy** contribution.
- **Dashboard** ‚Äî Line/Bar/Pie/Gauge charts with consistent legends/units and accessible defaults.
- **Exports** ‚Äî One‚Äëclick Markdown/PDF/PPTX for shareable evidence.

---

## Architecture
```
UI (Vercel)  ‚Üí  API (Render)  ‚Üí  Evaluator  ‚Üí  Metrics Store  ‚Üí  KPI Dashboard
       ‚Üë              ‚Üì                ‚Üì               ‚Üë
   Prompt Enhancer ‚Üí Candidate Generation ‚Üí Scoring ‚Üí Version Evolution
```

- **Enhancer** converts user intent into structured prompts and can auto‚Äëenable CoT when needed.  
- **Evaluator** runs the test suite and emits scores (Accuracy, F1, etc.).  
- **Dashboard** visualizes KPIs and the evolution timeline.

---

## Project Structure (Cloud)
```
Promptly/
‚îú‚îÄ frontend/        # React/Vite (or similar) UI
‚îú‚îÄ backend/         # Node/Express (or similar) API & evaluator
‚îî‚îÄ others/          # Docs, diagrams, samples, scripts
```
**Demo mode** ‚Äî Static UI preview (`index.html` can be opened directly).  
**Cloud mode** ‚Äî Split frontend/backed; deploy frontend on Vercel and backend on Render.

> Packaging convention
> - **Demo version**: must include an `index.html` at the root for one‚Äëclick preview.
> - **Cloud version**: must include top‚Äëlevel folders `backend/`, `frontend/`, `others/`.

---

## Quickstart

### A) Demo (Static UI)
1. Download the demo package and open `index.html` in your browser.  
2. Load the sample **Spec** and **Tests** to preview the workflow.  
3. KPIs and charts render placeholders until linked to backend data.

### B) Cloud (Vercel + Render)

**Backend**
```bash
cd backend
cp .env.example .env
# Add keys you plan to use:
#   OPENAI_API_KEY=...  (optional) ANTHROPIC_API_KEY=...  GEMINI_API_KEY=...
# If using a database:  DATABASE_URL=...
npm install
npm run dev      # or: npm run start
```

**Frontend**
```bash
cd frontend
npm install
# Configure API base
echo "VITE_API_BASE=http://localhost:10000" > .env
npm run dev
```

**Deploy**
- **Vercel (Frontend)** ‚Äî import repo ‚Üí set `VITE_API_BASE` ‚Üí deploy.  
- **Render (Backend)** ‚Äî add environment variables ‚Üí use platform `$PORT` ‚Üí deploy.

---

## Environment Variables
```
# Common
NODE_ENV=production
PORT=           # use platform-injected PORT on Render

# Providers (pick what you use)
OPENAI_API_KEY=...
ANTHROPIC_API_KEY=...
GEMINI_API_KEY=...

# Optional
DATABASE_URL=...
JWT_SECRET=...
METRICS_WRITE_KEY=...
VITE_API_BASE=https://your-backend.onrender.com
```

---

## Usage Flow
1. **Define Spec** ‚Äî Goal, constraints, quality bar, and tolerances.  
2. **Write Tests** ‚Äî A compact but representative set with gold answers.  
3. **Run Optimize** ‚Äî Explore prompts/parameters and score candidates automatically.  
4. **Review Evidence** ‚Äî Inspect KPI cards, trend charts, and the ŒîAccuracy evolution timeline.  
5. **Export & Share** ‚Äî Package the winning prompt and evidence as Markdown/PDF/PPTX.

---

## KPIs
- Accuracy ¬∑ F1 ¬∑ Pass Rate ¬∑ Token Cost ¬∑ Progress%  
- Optional: A/B comparisons and cost‚Äëquality trade‚Äëoffs.

---

## Roadmap
- **v0.5.x** ‚Äî UI polish, evolution timeline, data binding, export templates.  
- **v0.6** ‚Äî A/B testing, team collaboration, audit trails.

---

## Contributing
Issues and PRs are welcome. Please include a minimal repro with screenshots/screencasts.

---

## ü™™ License

¬© 2025 Tiger Yang‚Äî Released under the MIT License.  
Use, modify, distribute, or remix freely under the same open terms.  
Attribution is appreciated but not required.  

This project embodies an open-source spirit ‚Äî designed to inspire,  
build upon, and evolve through collective creativity.  

---

### MIT License

Copyright (c) 2025 Tiger

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal
in the Software without restriction, including without limitation the rights   
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell      
copies of the Software, and to permit persons to whom the Software is          
furnished to do so, subject to the following conditions:                       

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.                                

THE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR     
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,       
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE   
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER        
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,  
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE  
SOFTWARE.

---

## Acknowledgments
Lucide icons ¬∑ Inter font ¬∑ Vercel ¬∑ Render.
